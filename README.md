# Automata Theory - Complete Notes (Units 1 to 6)

---

## Unit 1: Regular Languages and Finite Automata

### 1. Regular Expressions and Regular Languages

- Regular expressions describe regular languages.
- Regular languages are those recognized by finite automata.

### 2. Finite Automata (FA)

- **Deterministic Finite Automaton (DFA)**: 
  5-tuple \( (Q, \Sigma, \delta, q_0, F) \), where:
  - \(Q\) = finite set of states
  - \(\Sigma\) = input alphabet
  - \(\delta: Q \times \Sigma \to Q\) = transition function
  - \(q_0 \in Q\) = start state
  - \(F \subseteq Q\) = set of final states

- **Nondeterministic Finite Automaton (NFA)**:
  Like DFA, but \(\delta\) maps to subsets of states, allowing multiple or zero transitions for input symbols.

- **\(\varepsilon\)-NFA**:
  NFA allowing transitions on empty string \(\varepsilon\).

### 3. Union, Intersection & Complement of Regular Languages

- Regular languages are closed under union, intersection, and complement.
- Operations can be implemented via product automata or state set transformations.

### 4. Applications of Finite Automata

- Lexical analyzers in compilers
- Pattern matching (e.g., grep)
- Network protocol validation

### 5. Output Producing FAs: Mealy and Moore Machines

- **Mealy Machine:** Output depends on state and input.
- **Moore Machine:** Output depends only on state.

---

## Unit 2: Nondeterminism and Kleene's Theorem

### 1. Nondeterministic Finite Automata (NFA)

- Automata allowing multiple transitions per symbol and multiple current states.
- Equivalent in power to DFA.

### 2. NFA with Null (\(\varepsilon\)) Transitions

- Transitions possible without consuming input symbols.
- Can be converted to NFA without \(\varepsilon\)-moves.

### 3. Equivalence of FAs

- Every NFA has an equivalent DFA (subset construction).
- DFA may have exponentially more states.

### 4. Kleene's Theorem

- **Part I (Proof):** Regular expressions and finite automata describe the same class of languages.
- **Part II (Statement):** Every language accepted by a finite automaton can be described by a regular expression.

### 5. Minimal State Finite Automata

- States can be merged using equivalence relations (Myhill-Nerode theorem).
- Minimization algorithms reduce DFA to minimal number of states.

---

## Unit 3: Context Free Grammar (CFG) and Normal Forms

### 1. Context-Free Grammar (CFG)

- \( G = (V, \Sigma, R, S) \), where:
  - \(V\): variables (non-terminals)
  - \(\Sigma\): terminals
  - \(R\): productions \( A \to \alpha \), \(A \in V\), \(\alpha \in (V \cup \Sigma)^*\)
  - \(S\): start symbol

### 2. Types of Grammar (Chomsky Hierarchy)

- Type 3: Regular Grammar
- Type 2: Context-Free Grammar
- Type 1: Context-Sensitive Grammar
- Type 0: Recursively Enumerable Grammar

### 3. Derivation Trees and Ambiguity

- Derivation tree represents parse structure.
- Grammar is ambiguous if some string has multiple distinct parse trees.

### 4. Union, Concatenation, Kleene Star of CFLs

- CFLs are closed under union, concatenation, and Kleene star.

### 5. Normal Forms

- **Chomsky Normal Form (CNF):** All productions are \(A \to BC\) or \(A \to a\).
- **Greibach Normal Form (GNF):** Productions \(A \to a \alpha\), where \(a\) is terminal.
- **Backus-Naur Form (BNF):** Standard notation for writing grammars.

---

## Unit 4: Pushdown Automata (PDA) and Parsing

### 1. Pushdown Automaton (PDA)

- \(M = (Q, \Sigma, \Gamma, \delta, q_0, Z_0, F)\)
- \(Q\): states, \(\Sigma\): input alphabet, \(\Gamma\): stack alphabet
- \(\delta: Q \times (\Sigma \cup \{\varepsilon\}) \times \Gamma \to 2^{Q \times \Gamma^*}\)
- \(q_0\): start state, \(Z_0\): initial stack symbol, \(F\): final states

### 2. Deterministic PDA (DPDA) vs Non-deterministic PDA (NPDA)

- DPDA has at most one move per configuration.
- NPDA may have multiple choices.

### 3. CFG and PDA Equivalence Theorem

- Every CFL is recognized by some PDA, and every PDA recognizes a CFL.

### 4. Applications of PDA

- Parsing, syntax checking, modeling recursion.

### 5. Parsing Methods

- Top-Down Parsing (LL parsing, predictive)
- Bottom-Up Parsing (LR parsing, shift-reduce)

---

## Unit 5: Context-Free Languages (CFL)

### 1. CFL Definition

- Generated by CFGs.

### 2. Closure Properties

- Closed under union, concatenation, Kleene star.
- Not closed under intersection or complement (but intersection with regular languages is closed).

### 3. Pumping Lemma for CFL

- Used to prove non-context-freeness.

### 4. Examples

- \( \{a^n b^n c^n \mid n \geq 0\} \) is not a CFL.
- Palindromes form CFL.

---

## Unit 6: Turing Machines (TM)

### 1. TM Definition

- \( M = (Q, \Sigma, \Gamma, \delta, q_0, B, F) \)
- \(Q\): states, \(\Sigma\): input alphabet, \(\Gamma\): tape alphabet, \(B\): blank symbol
- \(\delta: Q \times \Gamma \to Q \times \Gamma \times \{L,R\}\)

### 2. TM as Language Acceptor

- Accepts input if TM halts in final state.

### 3. Computing Functions

- TM computes partial functions by transforming tape content.

### 4. TM Variants

- Multi-tape, multi-track, nondeterministic TM, Universal TM, etc.

### 5. Universal Turing Machine (UTM)

- Simulates any TM given input encoding of TM and string.

---

# End of Notes

---

